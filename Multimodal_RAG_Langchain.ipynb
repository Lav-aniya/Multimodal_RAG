{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRlSEbQbA9Rj"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "groq_api = userdata.get('groq_api_key')\n",
    "lc_api = userdata.get('lc_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inIHz8X93nWw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = lc_api\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"colab-test\"\n",
    "os.environ[\"GROQ_API_KEY\"] = groq_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nX8oVH7GBKTC",
    "outputId": "007a219f-2a18-40dc-e388-b24f07f27111"
   },
   "outputs": [],
   "source": [
    "!pip install -Uq \"unstructured[all-docs]\" pillow lxml\n",
    "!pip install -Uq chromadb tiktoken\n",
    "!pip install -Uq langchain langchain-community langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFiJ6VdyjYfK",
    "outputId": "380a327b-243d-4969-cd6c-b72355ef8f57"
   },
   "outputs": [],
   "source": [
    "# Install Poppler for PDF processing\n",
    "!apt-get install -y poppler-utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fLbGMxgx0lL"
   },
   "source": [
    "# Extract the data\n",
    "\n",
    "Extract the elemets of the PDF that we will be able to use in the retrieval process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U608iNcamL5A"
   },
   "source": [
    "### Partition PDF text, images or tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "087089cfe0094f5a94a7f9cd6738f933",
      "34a6b8bb60bf467497c309ea4a511368",
      "7402a7e4dcc843b6ac581dd1e7e567c1",
      "660fca96908545f28c8b9fff0952a46d",
      "38aef22d26484aeba62fc6bfe4c8c5bc",
      "df0cb101e670492ba6386d10a8cd3a29",
      "579af6adc8254bf993a0aa4db65b6b44",
      "6a0e906c9c024ef3adc60fba575da98e",
      "4c55d1ca1e734ee48c512bc5cef16d3e",
      "5a4980238eea4ec980e9f6cdcde27e36",
      "27b32d31be67475ea20167bb6bf18e2f"
     ]
    },
    "id": "cv7pJJ0Xmki2",
    "outputId": "672c8ea8-adb8-40c6-cc56-3ad8d9dd519f"
   },
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "output_path = \"/content/drive/MyDrive/storypdf/\"\n",
    "file_path = output_path + 'short-story.pdf'\n",
    "\n",
    "chunks = partition_pdf(\n",
    "    filename = file_path,\n",
    "    #infer_table_structure=True,               # extract tables\n",
    "    #strategy='hi_res',                        # mandatory to infer tables\n",
    "\n",
    "    extract_image_block_types=[\"Image\"],      # Add 'Table' to list to extract image of tables\n",
    "    image_output_dir_path=\"/content/drive/MyDrive/storypdf/\",        # if None, images and tables will saved in base64\n",
    "\n",
    "    extract_image_block_to_payload=True,      # if true, will extract base64 for API usage\n",
    "\n",
    "    chunking_strategy=\"by_title\",             # or'basic'\n",
    "    max_characters=10000,                     # defaults to 500\n",
    "    combine_text_under_n_chars=2000,          # defaults to 0\n",
    "    new_after_n_chars=6000,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPxMDVBLmivA",
    "outputId": "2c5f0c3d-5e4e-4223-ac52-52408b3dd416"
   },
   "outputs": [],
   "source": [
    "# we got 1 types of elements from the partition_pdf function\n",
    "set([str(type(el)) for el in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBmpheWmlxnx",
    "outputId": "b07fea49-9dc8-4d1f-fd34-9e871f7da0fc"
   },
   "outputs": [],
   "source": [
    "# Each CompositeElement containes a bunch of related elements.\n",
    "# This makes it easy to use these elements together in a RAG pipeline.\n",
    "\n",
    "chunks[1].metadata.orig_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z60XQUkDmkbP",
    "outputId": "f353b27b-c380-4b1d-e44d-bf3ae0e17f6d"
   },
   "outputs": [],
   "source": [
    "# This is what an extracted image looks like.\n",
    "# It contains the base64 representation only because we set the param extract_image_block_to_payload=True\n",
    "\n",
    "elements = chunks[1].metadata.orig_elements\n",
    "chunk_images = [el for el in elements if 'Image' in str(type(el))]\n",
    "chunk_images[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3chAxJ9GuNp8"
   },
   "source": [
    "### Separate extracted elements into text, images and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAja-KOpuU7D"
   },
   "outputs": [],
   "source": [
    "# separate tables from texts\n",
    "tables = []\n",
    "texts = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    if \"Table\" in str(type(chunk)):\n",
    "      tables.append(chunk)\n",
    "\n",
    "    if \"CompositeElement\" in str(type(chunk)):\n",
    "      texts.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TK04tk6OvBA8"
   },
   "outputs": [],
   "source": [
    "# Get the images from the CompositeElement objects\n",
    "\n",
    "def get_images_base64(chunks):\n",
    "  images_b64 = []\n",
    "  for chunk in chunks:\n",
    "    if \"CompositeElement\" in str(type(chunk)):\n",
    "      chunk_els = chunk.metadata.orig_elements\n",
    "      for el in chunk_els:\n",
    "        if \"Image\" in str(type(el)):\n",
    "          images_b64.append(el.metadata.image_base64)\n",
    "  return images_b64\n",
    "\n",
    "images = get_images_base64(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWDOID4SwK_k"
   },
   "source": [
    "### Check what the images look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "vF_j0s74wPgB",
    "outputId": "660cd120-80e3-4688-d873-69d29bb5de7e"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def display_base64_image(base64_code):\n",
    "  # Decode the base64 string to binary\n",
    "  image_data = base64.b64decode(base64_code)\n",
    "  # Display the image\n",
    "  display(Image(data=image_data))\n",
    "\n",
    "display_base64_image(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2ZWp9DExcf0"
   },
   "source": [
    "# Summarize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_lss2enyLbK"
   },
   "source": [
    "### text and table summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRnRDNdPyRM_"
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQOxaFl4yr7Q"
   },
   "outputs": [],
   "source": [
    "# prompt\n",
    "prompt_text = \"\"\"\n",
    "You are an assistant tasked with summarizing tables and text.\n",
    "Give a concise summary of the table or text.\n",
    "\n",
    "Respond only with the summary, no additionnal comment.\n",
    "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
    "Just give the summary as it is.\n",
    "\n",
    "Table or text chunk: {element}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Summary Chain\n",
    "model = ChatGroq(temperature=0.5, model=\"llama-3.1-8b-instant\")\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wJ2nzSO15rF",
    "outputId": "0214db0e-9dd2-4330-880e-e63f90461843"
   },
   "outputs": [],
   "source": [
    "# Summarize text\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 3})\n",
    "\n",
    "# Summarize tables\n",
    "tables_html = [table.metadata.text_as_html for table in tables]\n",
    "table_summaries = summarize_chain.batch(tables_html, {\"max_concurrency\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KR51k--16Kw",
    "outputId": "280c2416-3cf6-44f3-ab9c-60531409601e"
   },
   "outputs": [],
   "source": [
    "table_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqWmk9bT4n4v"
   },
   "source": [
    "### Image summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5n2TlFtw4hDf"
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Describe the image in detail. For context,\n",
    "              the image part of the story for kids.\"\"\"\n",
    "messages = [\n",
    "    (\n",
    "        \"user\",\n",
    "        [\n",
    "            {\"type\": \"text\", \"text\": prompt_template},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "model = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "image_summaries = chain.batch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOKqIkhK9z4v",
    "outputId": "0ca8dc3b-d99b-48ef-e4d1-6dfe54a4c1c5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Create a prompt template with a placeholder for the image\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"user\",\n",
    "        [\n",
    "            {\"type\": \"text\", \"text\": \"\"\"Describe the image in detail. For context,\n",
    "              the image part of the story for kids.\"\"\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "])\n",
    "\n",
    "# 2. Your list of base64 images (strip whitespace if needed / img.strip())\n",
    "# Example: images = [\"/9j/4AAQSkZJRgABAQ...\", \"iVBORw0KGgoAAAANSUhEUg...\"]\n",
    "image_dicts = [{\"image\": img} for img in images]\n",
    "\n",
    "# 3. Setup the chain\n",
    "model = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# 4. Run in batch\n",
    "image_summaries = chain.batch(image_dicts)\n",
    "\n",
    "# 5. Print results\n",
    "#for i, summary in enumerate(image_summaries):\n",
    "#    print(f\"\\n📄 Image {i+1} Summary:\\n{summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HFnzXF6IbCb",
    "outputId": "764611c8-2456-4565-e719-66eac68b36a3"
   },
   "outputs": [],
   "source": [
    "print(image_summaries[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVArzSqqKETY"
   },
   "source": [
    "# Load data and summaries to vectorestore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_KtEBlWKPhv"
   },
   "source": [
    "### Create the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9WS4hnTOjvG",
    "outputId": "59abdc74-e365-4863-b4dc-9ae240616f90"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424,
     "referenced_widgets": [
      "0dc74664e75c4ac1a74095f83c7fca55",
      "d9d1a3b9ac9845dba086d3ed8cbbc2f7",
      "a19c7fbd4c994361a175e12f5db8416d",
      "398a676eb7c2498a8af0f0a510a84a1e",
      "5d37d820dd9c49968b6d1db6ca15f708",
      "c4f9673553c74b599d23bfe994c05f2a",
      "abbf856c31784dd1a558db6fe2d042c7",
      "603e12c69b4144b28c24b9cca9d7775c",
      "3eeaf46572e14156a7a0768c0cd8a0cd",
      "162399dcdfc046ddb4f12a7355c4fad2",
      "660063f2919943b2b728004e42ee3f18",
      "a896e5061922454abcd38748713004e6",
      "b9f50bcfc7c74025b78c212cd6279695",
      "48b04762ca644c2db7f883936a1a2490",
      "39dd95b946d1435a98499d7e13539a36",
      "008d49f0c8094ce6a22ea92def1cb36a",
      "e11c29ef6d364715937764f957eef93d",
      "fc35a46eb57141a5ab12f8af19c7213f",
      "50ad2bca8518465a96918bfe0d229bb2",
      "4588a85599d8435fb112434c0fc45ff4",
      "0ec7f4c862be47908c94618de5eff953",
      "57c86656b5d14ec1a7372f1172da43a2",
      "8d1515b8abef4d34b3314b4b5949b64c",
      "38a4f13697ae408f8729fdd0fe89c60f",
      "3a1d3bf924f841028d5621af391e9512",
      "b7060789f5b840e890cffb0831a7b231",
      "250674a97f6f48e28c021fcaa454c1d8",
      "bdf83657b8c84429bd8cb59e63372507",
      "1123a6e4111242b28a7e74a5434d2d12",
      "c89bbd613973485c8296a50e7b687332",
      "908a00d748a04269bd473488ec9dc716",
      "db8db652ab47415eb2d42ac2ae5fc26f",
      "fcb8a94ad6ff4e59a8635cf389dc9663",
      "579f0686635848a2a270c6cc0a6aafff",
      "72d83d83a69849ed8535932335eb24de",
      "1843af7991214e65a24fcbda32bdfe38",
      "423d1e4dedfa4f19b743fc1ca16dece6",
      "98dd08ddfd1f48d5ae37b8b83511f687",
      "ae049f097bad436180bdc2baf7282c70",
      "a22537b0168b4b1db64b5283088eeb99",
      "be0b0642289a4dff944ee3d6ad80c281",
      "c5d8428d4b20495fb492587d28068704",
      "a11c6cda97de40758ecbcbbc501083d2",
      "cc2a144551bb48a4aac79e16e613af19",
      "d75aa50ed3e041718e0fa18d4d211616",
      "8c0bce07622d492591d4dc9f23d925de",
      "903e47cbdc6b458ba4276076b8e3dfc6",
      "58e9168f78f74b2d9a6eeac4ff5b41a5",
      "b248340eb5004a46a5c98e4b8cb780e8",
      "8ad9c6a891e341089d155d2a954db570",
      "d25a9a189b304b0689f62f8e9ded2be6",
      "dc1917a3376c4e17b5faf8d626e344b8",
      "a2bdaf5be31640598e172f337c7f946a",
      "614b3577b51b46acb6cdad17df5bd89e",
      "e1819a6d965c4fc1a18905f080e9dc98",
      "3b1ae7564f2b4f1a9c12945e63ed8712",
      "61bcce4281584773a2381fe7b7bd921d",
      "a6e29c18da464d068a48140a57c45109",
      "701f063c565648a4868d34a08f426f98",
      "90a0b60be17847cfa2e2481d7a11185c",
      "2a4a4b9c30dd4b47bc7b446bfa38a916",
      "409af8dce68742d4b13ea796cfc3342b",
      "4938dabffe964ed7bfcb1c17eb2423f1",
      "04ea30a72cab4c3c9a58f98a3f18e9c0",
      "3d622001548345258f727613e3c3a462",
      "4c876d20cc944fd0b93b5197776343f8",
      "e64f54e07edb41a2b612d34a02ff87e5",
      "bc743679e36f4f62a866c4094d8509b0",
      "7a05844c089941d0a0afcd1934cac0f4",
      "cdaf63959e02463e8bf936daf74a23d5",
      "9367ea1f1cea494e8a6249efc04611d9",
      "c10b606070004816a7bad1cbf60e94ca",
      "10ec3f6dacc941349ab2aef621520d60",
      "5a688698d8524043a5e7e269b936f955",
      "4b8bcb9bf2e94ac0acba52c5f9dfa3a1",
      "8c2e9633e6594cfaba0c316c96a70524",
      "194a45b4d2c940d4b02d66e7e9e2cb86",
      "91fd8d6683f44b7596aec29a939f00a2",
      "0b5a9b5031f24a2387d2d81fe6144f76",
      "6c4fcbf2ec714f778a6f0333448e633d",
      "51202078ee514b0eb2631f9d20d10954",
      "be4df4f09e504d0dba029f7f4b8f9b27",
      "1aea1f95eddd4fd0ba220aeee1f0746a",
      "fb0d43579acb4279959c06b36546665d",
      "4012c2bb944540ab9a2836ca1dcafa48",
      "0a08a74faa0c44f7b88edcb45031f765",
      "66bd98f9e7334ffcb3bb44c31913585c",
      "d1f003d74f5540cbb5d849fbeeea771a",
      "ac79fbbebd264adda0773fd72b7e4a21",
      "23edc7c68c5e4b28aee89f8345e0481f",
      "720a6b3a2b394d31934381a672cde2df",
      "5fce4cce38a84391b74a547a89b6d556",
      "b824e353e30b43a1b044725a98bcc580",
      "b58f6a62e7f140a483133b85a00120a3",
      "acf2e7f7c05f442f8db4b473821f184e",
      "5da1a0e281ed4a42b69eb7546cca2018",
      "28057ae8f7b64c45ba13407899776226",
      "2f9d211ad42d421687f780a456ab70f7",
      "e1acdd07b38d40c78179b9bca4c4ac92",
      "9790541231e0424c946d1a0b7770daaf",
      "042039baaaff44f6810ce0e429270fe9",
      "a3ff66aa1ec042e18b7371aa1ebd3e00",
      "8f1683e4fd634b929ea7bdb29bdb71f1",
      "14aece15f697485bba8927fd5397bc53",
      "f3184458f16b4598aff80759acc5b2b1",
      "0d44e93d70f4458fa78d54b28f68f25e",
      "23657e91c8804f6e8b72bf2c04e48907",
      "eff2f3e66e0941de911773e1cb502642",
      "cc7f5dc1fa204d2f963b4a1b4477a9d6",
      "f15a4f61d4bf4f31be810e510fc72f22",
      "585630684b8c4d7aa12002aeb58ab257",
      "4192501e652a41d991bbda3211bca823",
      "7d0782fece4445f68a2f420829d3fe09",
      "14bef6061a1a4187b54d5c7b1e3016e8",
      "3e7cc190c49b4216abf928eccc635b28",
      "8fe7d70315fb411e82f0c621e63af969",
      "c7d1a002c7d34074bf3ffe9f6a445ed9",
      "d9ded724083d45bb943cc21cea60ff72",
      "3cce4140e5214735bbabef801e7380fc",
      "80e50aaf734e4bc786ad434c60b7a351",
      "b793c8a92d154ca88e3e530d0f4a92f5"
     ]
    },
    "id": "viAjaXzKOnr-",
    "outputId": "9d50194f-c3f1-40e4-beeb-cd05be953466"
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrOmxqoRL5uP"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhN-I8qeKI-W"
   },
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "#from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-exp-03-07\")\n",
    "embeddings = hf\n",
    "vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=embeddings)\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriver ( empty to start )\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geUoe46DP8aP"
   },
   "source": [
    "### Load the sumaries and link them to the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hajyNnH6QEBN"
   },
   "outputs": [],
   "source": [
    "# Add texts\n",
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "summary_texts = [\n",
    "    Document(page_content=summary, metadata={id_key: doc_ids[i]}) for i, summary in enumerate(text_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "# Add image summaries\n",
    "img_ids = [str(uuid.uuid4()) for _ in images]\n",
    "summary_img = [\n",
    "    Document(page_content=summary, metadata={id_key: img_ids[i]}) for i, summary in enumerate( image_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_img)\n",
    "retriever.docstore.mset(list(zip(img_ids, images)))\n",
    "\n",
    "# Add tables\n",
    "#table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "#summary_tables = [\n",
    "#    Document(page_content=summary, metadata={id_key: table_ids[i]}) for i, summary in enumerate(table_summaries)\n",
    "#]\n",
    "#retriever.vectorstore.add_documents(summary_tables)\n",
    "#retriever.docstore.mset(list(zip(table_ids, tables)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr-JI9DlNPRW"
   },
   "source": [
    "### Check retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKBHNyaEKSJp"
   },
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "docs = retriever.invoke(\n",
    "    \"Who is the little princess?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugDz5pvQNSae",
    "outputId": "e6f62b8a-316e-4ce3-c148-a2df628a85ef"
   },
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "  print(str(doc) + \"\\n\\n\" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqTgwU95POSh"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "def extract_page_numbers_from_chunk(chunk):\n",
    "  elements = chunk.metadata.orig_elements\n",
    "\n",
    "  page_numbers = set()\n",
    "  for element in elements:\n",
    "    page_numbers.add(element.metadata.page_number)\n",
    "\n",
    "  return page_numbers\n",
    "\n",
    "extract_page_numbers_from_chunk(chunks[0])\n",
    "\n",
    "def display_chunk_pages(chunk):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHqLXGv_Wx0d"
   },
   "source": [
    "# RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu_w8OpLbtyp"
   },
   "outputs": [],
   "source": [
    "\n",
    "from base64 import b64decode\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkqPjecwcsrY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67hwua-yW0OZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def parse_docs(docs):\n",
    "  \"\"\"split base64-encoded images and texts\"\"\"\n",
    "  b64 = []\n",
    "  text = []\n",
    "  for doc in docs:\n",
    "    try:\n",
    "      b64decode(doc)\n",
    "      b64.append(doc)\n",
    "    except Exception as e:\n",
    "      text.append(doc)\n",
    "  return {\"images\": b64, \"texts\": text}\n",
    "\n",
    "def build_prompt(kwargs):\n",
    "    docs_by_type = kwargs[\"context\"]\n",
    "    user_question = kwargs[\"question\"]\n",
    "\n",
    "    context_text = \"\"\n",
    "    if len(docs_by_type[\"texts\"]) > 0 :\n",
    "      for text_element in docs_by_type[\"texts\"]:\n",
    "        context_text += text_element.text\n",
    "\n",
    "    #construct prompt with context (including images)\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the question based only on the following context, which can include text, and the below image.\n",
    "    Context: {context_text}\n",
    "    Question: {user_question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_content = [{\"type\": \"text\", \"text\": prompt_template}]\n",
    "\n",
    "    if len(docs_by_type[\"images\"]) > 0:\n",
    "      for image in docs_by_type[\"images\"]:\n",
    "        prompt_content.append(\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "            }\n",
    "        )\n",
    "\n",
    "      return ChatPromptTemplate.from_messages(\n",
    "      [\n",
    "        HumanMessage(content = prompt_content)\n",
    "      ]\n",
    "  )\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(parse_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(build_prompt)\n",
    "    | ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_with_sources = {\n",
    "    \"context\": retriever | RunnableLambda(parse_docs),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "} | RunnablePassthrough().assign(\n",
    "    response=(\n",
    "        RunnableLambda(build_prompt)\n",
    "        | ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EP2Ue0EbmXx",
    "outputId": "82646ac2-3cfd-4408-ddbf-9c5514c3a124"
   },
   "outputs": [],
   "source": [
    "response = chain.invoke(\n",
    "    \" what is the second story about?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tF-B7nKFdnzX",
    "outputId": "108ea419-5c80-429a-8ec5-1ad39408d9d7"
   },
   "outputs": [],
   "source": [
    "response = chain_with_sources.invoke(\n",
    "    \"summarise the last story and show the images\"\n",
    ")\n",
    "print(\"response:\", response['response'])\n",
    "\n",
    "print(\"\\n\\ncontext:\")\n",
    "for text in response['context']['texts']:\n",
    "    print(text.text)\n",
    "    print(\"Page number: \", text.metadata.page_number)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "for image in response['context']['images']:\n",
    "    display_base64_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7sL78bIenC5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "6fLbGMxgx0lL",
    "U608iNcamL5A",
    "3chAxJ9GuNp8",
    "tWDOID4SwK_k"
   ],
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
